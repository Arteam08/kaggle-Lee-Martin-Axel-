{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "def load_data(path, verbose=False):\n",
    "    li = []\n",
    "    for filename in os.listdir(path):\n",
    "        df = pd.read_csv(os.path.join(path, filename))\n",
    "        li.append(df)\n",
    "    output = pd.concat(li)\n",
    "    if verbose:\n",
    "        print(output.head())\n",
    "        print(f'The shape of the data is: {output.shape}')\n",
    "    return output\n",
    "\n",
    "# Define paths\n",
    "path_to_data = \"../../challenge_data/\"\n",
    "path_to_training_tweets = os.path.join(path_to_data, \"train_tweets\")\n",
    "path_to_eval_tweets = os.path.join(path_to_data, \"eval_tweets\")\n",
    "output_path = \"evaluation_predictions.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID  MatchID  PeriodID  EventType      Timestamp  \\\n",
      "0          2_0        2         0          0  1403538600000   \n",
      "1          2_0        2         0          0  1403538600000   \n",
      "2          2_0        2         0          0  1403538600000   \n",
      "3          2_0        2         0          0  1403538600000   \n",
      "4          2_0        2         0          0  1403538600000   \n",
      "...        ...      ...       ...        ...            ...   \n",
      "256440  17_129       17       129          1  1403805600000   \n",
      "256441  17_129       17       129          1  1403805600000   \n",
      "256442  17_129       17       129          1  1403805600000   \n",
      "256443  17_129       17       129          1  1403805600000   \n",
      "256444  17_129       17       129          1  1403805600000   \n",
      "\n",
      "                                                    Tweet  \n",
      "0       RT @soccerdotcom: If #ESP beats #AUS we'll giv...  \n",
      "1       Visit the #SITEP official web site here http:/...  \n",
      "2       RT @soccerdotcom: If #ESP beats #AUS we'll giv...  \n",
      "3       RT @worldsoccershop: If there is a winner in t...  \n",
      "4       RT @soccerdotcom: If #AUS beats #ESP we'll giv...  \n",
      "...                                                   ...  \n",
      "256440  RT @BBCSport: Portugal fourth team in top 10 o...  \n",
      "256441  RT @NBCSports: USA MOVES ON! Germany beats #US...  \n",
      "256442  Ronaldo could have easily scored 4-5 goals ton...  \n",
      "256443  RT @TheSelenatorBoy: Ppl getting mad bc Pepe i...  \n",
      "256444  We grew game after game so we won this one. Al...  \n",
      "\n",
      "[5056050 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess training data\n",
    "df_train = load_data(path_to_training_tweets)\n",
    "\n",
    "print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID  MatchID  PeriodID  EventType      Timestamp  \\\n",
      "0          2_0        2         0          0  1403538600000   \n",
      "1          2_0        2         0          0  1403538600000   \n",
      "2          2_0        2         0          0  1403538600000   \n",
      "3          2_0        2         0          0  1403538600000   \n",
      "4          2_0        2         0          0  1403538600000   \n",
      "...        ...      ...       ...        ...            ...   \n",
      "256440  17_129       17       129          1  1403805600000   \n",
      "256441  17_129       17       129          1  1403805600000   \n",
      "256442  17_129       17       129          1  1403805600000   \n",
      "256443  17_129       17       129          1  1403805600000   \n",
      "256444  17_129       17       129          1  1403805600000   \n",
      "\n",
      "                                                    Tweet  random_id  \n",
      "0       RT @soccerdotcom: If #ESP beats #AUS we'll giv...         20  \n",
      "1       Visit the #SITEP official web site here http:/...         29  \n",
      "2       RT @soccerdotcom: If #ESP beats #AUS we'll giv...         16  \n",
      "3       RT @worldsoccershop: If there is a winner in t...          3  \n",
      "4       RT @soccerdotcom: If #AUS beats #ESP we'll giv...          7  \n",
      "...                                                   ...        ...  \n",
      "256440  RT @BBCSport: Portugal fourth team in top 10 o...         24  \n",
      "256441  RT @NBCSports: USA MOVES ON! Germany beats #US...          9  \n",
      "256442  Ronaldo could have easily scored 4-5 goals ton...          5  \n",
      "256443  RT @TheSelenatorBoy: Ppl getting mad bc Pepe i...         12  \n",
      "256444  We grew game after game so we won this one. Al...          0  \n",
      "\n",
      "[5056050 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "MAX_SUBGROUP = 30\n",
    "\n",
    "# Create an array of random integers in {0, ..., MAX_SUBGROUP} of size len(df_train)\n",
    "df_train[\"random_id\"] = np.random.randint(0, MAX_SUBGROUP, len(df_train))\n",
    "\n",
    "print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ID  MatchID  PeriodID  \\\n",
      "0       0_0        0         0   \n",
      "1       0_0        0         0   \n",
      "2       0_0        0         0   \n",
      "3       0_0        0         0   \n",
      "4       0_0        0         0   \n",
      "...     ...      ...       ...   \n",
      "64097  8_99        8        99   \n",
      "64098  8_99        8        99   \n",
      "64099  8_99        8        99   \n",
      "64100  8_99        8        99   \n",
      "64101  8_99        8        99   \n",
      "\n",
      "                                                   Tweet  EventType  \n",
      "0      RT @trueSCRlife: If #Shaqiri scores vs #HON we...          0  \n",
      "1      RT @rogerfederer: Playing tomorrow on Center C...          0  \n",
      "2      The more goals France scores today the less go...          0  \n",
      "3      World Cup games at 4 pm ET: France-Ecuador on ...          0  \n",
      "4      RT @steveaoki: HONDURAS HERE WE COME! Line-up:...          0  \n",
      "...                                                  ...        ...  \n",
      "64097  RT @FIFAWorldCup: GOAL: #CMR 1-3 #BRA @fredgol...          1  \n",
      "64098  Vamos #BRA ready for #WorldCup2014 Switched ba...          1  \n",
      "64099  RT @Footy_Jokes: Neymar for #BRA\\n\\n35 Goals \\...          1  \n",
      "64100  Fred Reis.. #BRA #CAM #WORLDCUP2014 #FIFA2014 ...          1  \n",
      "64101  RT @Footy_Jokes: Neymar for #BRA\\n\\n35 Goals \\...          1  \n",
      "\n",
      "[64102 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Concatenate tweets\n",
    "df_train_bis = (\n",
    "    df_train\n",
    "    .groupby([\"ID\", \"MatchID\", \"PeriodID\", \"random_id\"], as_index=False)\n",
    "    .agg({\n",
    "        \"Tweet\": lambda x: \" \".join(x),\n",
    "        \"EventType\": \"first\"\n",
    "    })\n",
    "    .sort_values([\"ID\", \"MatchID\", \"PeriodID\", \"random_id\"])\n",
    ")\n",
    "\n",
    "# Drop the \"random_id\" column\n",
    "df_train_bis = df_train_bis.drop(columns=[\"random_id\"])\n",
    "\n",
    "print(df_train_bis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_bis[\"Tweet\"] = df_train_bis[\"Tweet\"].str.cat(sep=\" \")\n",
    "print(df_train_bis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Expr' object has no attribute 'apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m df_train_bis \u001b[38;5;241m=\u001b[39m df_train_bis\u001b[38;5;241m.\u001b[39mwith_columns(\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mConcatenated_Tweets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m(\u001b[38;5;28;01mlambda\u001b[39;00m x: re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[^a-zA-Z0-9\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, x))\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConcatenated_Tweets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Expr' object has no attribute 'apply'"
     ]
    }
   ],
   "source": [
    "df_train_bis = df_train_bis.with_columns(\n",
    "    pl.col(\"Concatenated_Tweets\").apply(lambda x: re.sub(r'[^a-zA-Z0-9\\s]', '', x)).alias(\"Concatenated_Tweets\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
